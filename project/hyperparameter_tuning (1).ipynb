{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1609014180091
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import dependencies\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1609014189184
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-131891\n",
      "Azure region: southcentralus\n",
      "Subscription id: 61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\n",
      "Resource group: aml-quickstarts-131891\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"capstone-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1609014203396
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: update the key to match the dataset name\n",
    "found = False\n",
    "key = \"diabetes-classification\"\n",
    "description_text = \"Diabetes datasets for capstone project\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True        \n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "        # Create Hyperdrive Dataset and register it into Workspace\n",
    "        url = 'https://raw.githubusercontent.com/purunep/Capstone/main/project/data/diabetes.csv'\n",
    "        dataset = Dataset.Tabular.from_delimited_files(url)        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()\n",
    "\n",
    "from train import clean_data\n",
    "[x_data, y_data] = clean_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1609014209237
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1609014220400
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "cpu_cluster_name = \"puru-compute-new\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
    "                                                           max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1609014228419
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.0-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from scikit-learn) (1.5.2)\n",
      "\u001b[31mERROR: azureml-train-automl-runtime 1.19.0 has requirement scikit-learn<0.23.0,>=0.19.0, but you'll have scikit-learn 0.24.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-runtime 1.19.0 has requirement scikit-learn<0.23.0,>=0.19.0, but you'll have scikit-learn 0.24.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed scikit-learn-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1609014237681
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "envit = Environment.get(workspace=ws,name='AzureML-Tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1609014240425
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment(Name: AzureML-Tutorial,\n",
      "Version: 60)\n"
     ]
    }
   ],
   "source": [
    "print(envit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ws.compute_targets['puru-compute-new']\n",
    "config  = ScriptRunConfig(source_directory='.',\n",
    "                         script='train.py',\n",
    "                         compute_target=target,\n",
    "                         environment=envit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8d7b0733a04a6fb18f4f86d7f0846d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/capstone-project/runs/capstone-project_1609018810_472dcd8d?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131891/workspaces/quick-starts-ws-131891\", \"run_id\": \"capstone-project_1609018810_472dcd8d\", \"run_properties\": {\"run_id\": \"capstone-project_1609018810_472dcd8d\", \"created_utc\": \"2020-12-26T21:40:16.305271Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"0ae0b77d-0996-46f9-ab90-8e169657f1bc\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-12-26T21:47:46.832848Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=GtZ%2Fyw1YBQyDrs4rjEezUggKS4Rbjvi5ZrBNfOeRpoQ%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=n4%2Fl5bwX4oUku4oHYaHnZvNVp%2FWB3vdY8THB83jkqTM%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=JT%2FjZWgc1JQG%2F36FadsU21ExbXV%2FrhDRgclujRpRdmg%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=hRUz7D5DDz9IHM3B8x7NqMrH1Ir5X0g27oRBC4CcgsU%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=lq5cRjy33SfEevz0e7XzCysGrGlkujvLmmCU6TWjmSw%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=lP3r3G5w0a0SuM4MY3WQ6mFbIs1RfEBjKeVcF39q6DI%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/106_azureml.log\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=FtOZnEVcAo6EHghww33THpQ7ykoM9JbXt0MH3dMiSds%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=I9UoZewcd3CnZvOAnoIzFWoA%2B0PjI3fI%2BQmbWNpkhys%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=P67MVT8NeuJJWFC%2B4Pfprx9EsbMzQ%2Bu5JE55wEqJf7I%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/dataprep/engine_spans_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/engine_spans_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl?sv=2019-02-02&sr=b&sig=1CE51TXB85LbPJxsVs6gl5fXLFjlYqRQDhK2THyD1l8%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/dataprep/python_span_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/python_span_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl?sv=2019-02-02&sr=b&sig=4O3hI0XUU5soUneRpGadu21V%2BQgZLgxy7axfzbYKfZ8%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=X3MScOukrRQjrBofw%2Fau1bnP6UFGSwoXbtRfsTVWnYs%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=K2mm%2FTiCZKu4LThG5rBsHYNA%2F8vbMhmch4qmmCkmnqM%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/dataprep/engine_spans_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl\", \"logs/azureml/dataprep/python_span_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl\"], [\"azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\"], [\"logs/azureml/106_azureml.log\"]], \"run_duration\": \"0:07:30\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Strength:\", \"run_id\": \"capstone-project_1609018810_472dcd8d\", \"categories\": [0], \"series\": [{\"data\": [1.0]}]}, {\"name\": \"Max iterations:\", \"run_id\": \"capstone-project_1609018810_472dcd8d\", \"categories\": [0], \"series\": [{\"data\": [100]}]}, {\"name\": \"Accuracy\", \"run_id\": \"capstone-project_1609018810_472dcd8d\", \"categories\": [0], \"series\": [{\"data\": [0.7467532467532467]}]}], \"run_logs\": \"2020-12-26 21:47:02,133|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2020-12-26 21:47:02,134|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2020-12-26 21:47:02,195|azureml.history._tracking.PythonWorkingDirectory|DEBUG|PySpark found in environment.\\n2020-12-26 21:47:02,196|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-12-26 21:47:02,606|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-12-26 21:47:02,606|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-12-26 21:47:02,607|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-12-26 21:47:02,607|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-12-26 21:47:02,607|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7fcc461242f0> for run source hyperdrive\\n2020-12-26 21:47:02,626|azureml.core|WARNING|Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 2.0.0 (/azureml-envs/azureml_a1736710baabf05d37337a101fa8d6d1/lib/python3.6/site-packages), Requirement.parse('pyarrow<2.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\\n2020-12-26 21:47:02,678|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7fcc460197b8> for run source azureml.PipelineRun\\n2020-12-26 21:47:02,687|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7fcc4601a268> for run source azureml.ReusedStepRun\\n2020-12-26 21:47:02,697|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7fcc4601a1e0> for run source azureml.StepRun\\n2020-12-26 21:47:02,707|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fcc4631ad90> for run source azureml.scriptrun\\n2020-12-26 21:47:02,739|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-26 21:47:02,748|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-12-26 21:47:02,748|azureml.core.authentication|DEBUG|Time to expire 1813993.25177 seconds\\n2020-12-26 21:47:02,748|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2020-12-26 21:47:02,748|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2020-12-26 21:47:02,801|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,801|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,801|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,802|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,802|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,802|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,802|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:02,842|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-26 21:47:02,842|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-26 21:47:02,918|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:02,919|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '0ae0b77d-0996-46f9-ab90-8e169657f1bc', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-12-26 21:47:02,919|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-26 21:47:03,970|azureml|DEBUG|Installed with mlflow version 1.12.1.\\n2020-12-26 21:47:03,971|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2020-12-26 21:47:03,973|azureml.mlflow|DEBUG|Creating a tracking uri in southcentralus.experiments.azureml.net for workspace /subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourceGroups/aml-quickstarts-131891/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-131891\\n2020-12-26 21:47:03,974|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2020-12-26 21:47:03,974|azureml.mlflow._internal.model_registry|DEBUG|Initializing the AzureMLflowModelRegistry\\n2020-12-26 21:47:03,974|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2020-12-26 21:47:03,974|azureml.mlflow|DEBUG|Setting MLflow run id env var with capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:03,974|azureml.mlflow|DEBUG|Setting Mlflow experiment with capstone-project\\n2020-12-26 21:47:03,975|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2020-12-26 21:47:03,976|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2020-12-26 21:47:03,976|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2020-12-26 21:47:03,976|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2020-12-26 21:47:04,102|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:04,104|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2020-12-26 21:47:04,104|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-26 21:47:04,256|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:04,257|azureml.WorkerPool|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml.RunStatusContext|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml.MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-12-26 21:47:04,257|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-12-26 21:47:04,258|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:04,258|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-26 21:47:04,258|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:20,524|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-12-26 21:47:20,525|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,525|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,526|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,526|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,526|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2020-12-26 21:47:20,559|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-26 21:47:20,559|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-26 21:47:20,640|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:20,641|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '0ae0b77d-0996-46f9-ab90-8e169657f1bc', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2020-12-26 21:47:20,641|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-26 21:47:20,642|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-26 21:47:20,643|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-26 21:47:20,643|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-26 21:47:20,811|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-26 21:47:20,811|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:20,811|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d to /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:20,812|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-131891/azureml/capstone-project_1609018810_472dcd8d/mounts/workspaceblobstore/azureml/capstone-project_1609018810_472dcd8d\\n2020-12-26 21:47:20,812|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-12-26 21:47:20,812|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-12-26 21:47:20,812|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-26 21:47:20,812|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-26 21:47:20,812|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-26 21:47:20,813|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-26 21:47:20,813|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:20,813|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:20,813|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-12-26 21:47:20,813|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-26 21:47:20,814|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:20,814|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-26 21:47:20,814|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:20,815|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-26 21:47:20,816|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-26 21:47:21,256|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:21,257|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,257|azureml.MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,257|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2020-12-26 21:47:21,258|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-26 21:47:21,259|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,259|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,259|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-26 21:47:21,259|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-26 21:47:21,317|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:21,317|azureml.RunStatusContext|DEBUG|[STOP]\\n2020-12-26 21:47:21,317|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,317|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,317|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,318|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,319|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-26 21:47:21,319|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-26 21:47:21,374|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:21,374|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,374|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-26 21:47:21,374|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2020-12-26 21:47:21,375|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:21,376|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-12-26 21:47:21,376|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-12-26 21:47:21,376|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2020-12-26 21:47:21,376|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-12-26 21:47:21,376|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-12-26 21:47:21,376|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-12-26 21:47:21,377|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2020-12-26 21:47:21,377|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-12-26 21:47:21,377|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-12-26 21:47:21,377|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2020-12-26 21:47:21,378|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-12-26 21:47:21,378|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-12-26 21:47:21,378|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2020-12-26 21:47:21,378|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-12-26 21:47:21,383|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-12-26 21:47:21,384|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2020-12-26 21:47:21,384|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2020-12-26 21:47:21,384|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2020-12-26 21:47:22,591|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:22,636|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2020-12-26 21:47:22,636|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2020-12-26 21:47:22,636|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2020-12-26 21:47:22,637|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00013399124145507812 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.25051069259643555 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.5009124279022217 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.7512671947479248 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 1.0016708374023438 seconds.\\n\\n2020-12-26 21:47:22,637|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:22,637|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2020-12-26 21:47:22,637|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2020-12-26 21:47:22,637|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2020-12-26 21:47:22,700|azureml._SubmittedRun#capstone-project_1609018810_472dcd8d.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2020-12-26 21:47:27,706|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2020-12-26 21:47:27,761|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2020-12-26 21:47:27,761|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2020-12-26 21:47:27,761|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2020-12-26 21:47:27,761|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: capstone-project_1609018810_472dcd8d\n",
      "Web View: https://ml.azure.com/experiments/capstone-project/runs/capstone-project_1609018810_472dcd8d?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131891/workspaces/quick-starts-ws-131891\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-12-26T21:44:57Z Starting output-watcher...\n",
      "2020-12-26T21:44:57Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2020-12-26T21:44:57Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2020-12-26T21:44:57Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d\n",
      "2c11b7cecaa5: Pulling fs layer\n",
      "04637fa56252: Pulling fs layer\n",
      "d6e6af23a0f3: Pulling fs layer\n",
      "b4a424de92ad: Pulling fs layer\n",
      "3e5d9ee64909: Pulling fs layer\n",
      "3a846111ff22: Pulling fs layer\n",
      "93a5020c6e19: Pulling fs layer\n",
      "360b353e68fd: Pulling fs layer\n",
      "ea4e2e1810f8: Pulling fs layer\n",
      "def12cf7de15: Pulling fs layer\n",
      "3ae6adfbdb11: Pulling fs layer\n",
      "2a21fbf2232e: Pulling fs layer\n",
      "c3b665eb1dfa: Pulling fs layer\n",
      "d9701991fc6b: Pulling fs layer\n",
      "a813f6841dbb: Pulling fs layer\n",
      "f4a625ee23f7: Pulling fs layer\n",
      "db94224120a3: Pulling fs layer\n",
      "be3820fbf9ab: Pulling fs layer\n",
      "def12cf7de15: Waiting\n",
      "3ae6adfbdb11: Waiting\n",
      "2a21fbf2232e: Waiting\n",
      "c3b665eb1dfa: Waiting\n",
      "d9701991fc6b: Waiting\n",
      "a813f6841dbb: Waiting\n",
      "f4a625ee23f7: Waiting\n",
      "db94224120a3: Waiting\n",
      "be3820fbf9ab: Waiting\n",
      "3e5d9ee64909: Waiting\n",
      "3a846111ff22: Waiting\n",
      "93a5020c6e19: Waiting\n",
      "360b353e68fd: Waiting\n",
      "ea4e2e1810f8: Waiting\n",
      "b4a424de92ad: Waiting\n",
      "04637fa56252: Download complete\n",
      "d6e6af23a0f3: Verifying Checksum\n",
      "d6e6af23a0f3: Download complete\n",
      "b4a424de92ad: Download complete\n",
      "2c11b7cecaa5: Verifying Checksum\n",
      "2c11b7cecaa5: Download complete\n",
      "93a5020c6e19: Verifying Checksum\n",
      "93a5020c6e19: Download complete\n",
      "3a846111ff22: Verifying Checksum\n",
      "3a846111ff22: Download complete\n",
      "3e5d9ee64909: Verifying Checksum\n",
      "3e5d9ee64909: Download complete\n",
      "360b353e68fd: Verifying Checksum\n",
      "360b353e68fd: Download complete\n",
      "def12cf7de15: Download complete\n",
      "3ae6adfbdb11: Verifying Checksum\n",
      "3ae6adfbdb11: Download complete\n",
      "2a21fbf2232e: Verifying Checksum\n",
      "2a21fbf2232e: Download complete\n",
      "ea4e2e1810f8: Verifying Checksum\n",
      "ea4e2e1810f8: Download complete\n",
      "c3b665eb1dfa: Download complete\n",
      "d9701991fc6b: Verifying Checksum\n",
      "d9701991fc6b: Download complete\n",
      "f4a625ee23f7: Download complete\n",
      "a813f6841dbb: Verifying Checksum\n",
      "a813f6841dbb: Download complete\n",
      "be3820fbf9ab: Verifying Checksum\n",
      "2c11b7cecaa5: Pull complete\n",
      "04637fa56252: Pull complete\n",
      "d6e6af23a0f3: Pull complete\n",
      "b4a424de92ad: Pull complete\n",
      "3e5d9ee64909: Pull complete\n",
      "3a846111ff22: Pull complete\n",
      "93a5020c6e19: Pull complete\n",
      "db94224120a3: Verifying Checksum\n",
      "db94224120a3: Download complete\n",
      "360b353e68fd: Pull complete\n",
      "ea4e2e1810f8: Pull complete\n",
      "def12cf7de15: Pull complete\n",
      "3ae6adfbdb11: Pull complete\n",
      "2a21fbf2232e: Pull complete\n",
      "c3b665eb1dfa: Pull complete\n",
      "d9701991fc6b: Pull complete\n",
      "a813f6841dbb: Pull complete\n",
      "f4a625ee23f7: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2020-12-26T21:46:53.926189] Entering job preparation.\n",
      "[2020-12-26T21:46:54.573453] Starting job preparation.\n",
      "[2020-12-26T21:46:54.573492] Extracting the control code.\n",
      "[2020-12-26T21:46:54.594744] fetching and extracting the control code on master node.\n",
      "[2020-12-26T21:46:54.594778] Starting extract_project.\n",
      "[2020-12-26T21:46:54.594815] Starting to extract zip file.\n",
      "[2020-12-26T21:46:55.316985] Finished extracting zip file.\n",
      "[2020-12-26T21:46:55.471828] Using urllib.request Python 3.0 or later\n",
      "[2020-12-26T21:46:55.471889] Start fetching snapshots.\n",
      "[2020-12-26T21:46:55.471934] Start fetching snapshot.\n",
      "[2020-12-26T21:46:55.471985] Retrieving project from snapshot: 6196c20f-725f-453a-bb52-df236c87bb64\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 50\n",
      "[2020-12-26T21:46:57.101401] Finished fetching snapshot.\n",
      "[2020-12-26T21:46:57.101435] Finished fetching snapshots.\n",
      "[2020-12-26T21:46:57.101449] Finished extract_project.\n",
      "[2020-12-26T21:46:57.112737] Finished fetching and extracting the control code.\n",
      "[2020-12-26T21:46:57.115773] downloadDataStore - Download from datastores if requested.\n",
      "[2020-12-26T21:46:57.116797] Start run_history_prep.\n",
      "[2020-12-26T21:46:57.168762] Entering context manager injector.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2020-12-26T21:47:32.958501] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 2.0.0 (/azureml-envs/azureml_a1736710baabf05d37337a101fa8d6d1/lib/python3.6/site-packages), Requirement.parse('pyarrow<2.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n",
      "[2020-12-26T21:47:34.174254] Starting job release\n",
      "[2020-12-26T21:47:34.175073] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 380\n",
      "[2020-12-26T21:47:34.175337] job release stage : upload_datastore starting...\n",
      "[2020-12-26T21:47:34.176145] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-12-26T21:47:34.176430] job release stage : execute_job_release starting...\n",
      "[2020-12-26T21:47:34.178524] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-12-26T21:47:34.178587] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-12-26T21:47:34.185986] Entering context manager injector.\n",
      "[2020-12-26T21:47:34.188885] job release stage : upload_datastore completed...\n",
      "[2020-12-26T21:47:35.039410] job release stage : send_run_telemetry starting...\n",
      "[2020-12-26T21:47:35.302123] job release stage : execute_job_release completed...\n",
      "[2020-12-26T21:47:36.696265] job release stage : send_run_telemetry completed...\n",
      "[2020-12-26T21:47:36.696515] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: capstone-project_1609018810_472dcd8d\n",
      "Web View: https://ml.azure.com/experiments/capstone-project/runs/capstone-project_1609018810_472dcd8d?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131891/workspaces/quick-starts-ws-131891\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'capstone-project_1609018810_472dcd8d',\n",
       " 'target': 'puru-compute-new',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-12-26T21:44:52.257163Z',\n",
       " 'endTimeUtc': '2020-12-26T21:47:46.832848Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '0ae0b77d-0996-46f9-ab90-8e169657f1bc',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'puru-compute-new',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'environment': {'name': 'AzureML-Tutorial',\n",
       "   'version': '60',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-core==1.19.0',\n",
       "        'azureml-defaults==1.19.0',\n",
       "        'azureml-telemetry==1.19.0',\n",
       "        'azureml-train-restclients-hyperdrive==1.19.0',\n",
       "        'azureml-train-core==1.19.0',\n",
       "        'azureml-widgets==1.19.0',\n",
       "        'azureml-pipeline-core==1.19.0',\n",
       "        'azureml-pipeline-steps==1.19.0',\n",
       "        'azureml-opendatasets==1.19.0',\n",
       "        'azureml-automl-core==1.19.0',\n",
       "        'azureml-automl-runtime==1.19.0',\n",
       "        'azureml-train-automl-client==1.19.0',\n",
       "        'azureml-train-automl-runtime==1.19.0',\n",
       "        'azureml-train-automl==1.19.0',\n",
       "        'azureml-train==1.19.0',\n",
       "        'azureml-sdk==1.19.0',\n",
       "        'azureml-interpret==1.19.0',\n",
       "        'azureml-tensorboard==1.19.0',\n",
       "        'azureml-mlflow==1.19.0',\n",
       "        'mlflow',\n",
       "        'sklearn-pandas']},\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'tqdm',\n",
       "      'scikit-learn',\n",
       "      'matplotlib'],\n",
       "     'name': 'azureml_a1736710baabf05d37337a101fa8d6d1'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/55_azureml-execution-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=GtZ%2Fyw1YBQyDrs4rjEezUggKS4Rbjvi5ZrBNfOeRpoQ%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/65_job_prep-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=n4%2Fl5bwX4oUku4oHYaHnZvNVp%2FWB3vdY8THB83jkqTM%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=JT%2FjZWgc1JQG%2F36FadsU21ExbXV%2FrhDRgclujRpRdmg%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/75_job_post-tvmps_0fa11b7d8b440ac593a926df752effeb38f7e7895f3c1640d77dae6a7b83a652_d.txt?sv=2019-02-02&sr=b&sig=hRUz7D5DDz9IHM3B8x7NqMrH1Ir5X0g27oRBC4CcgsU%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=lq5cRjy33SfEevz0e7XzCysGrGlkujvLmmCU6TWjmSw%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=lP3r3G5w0a0SuM4MY3WQ6mFbIs1RfEBjKeVcF39q6DI%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/106_azureml.log': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=FtOZnEVcAo6EHghww33THpQ7ykoM9JbXt0MH3dMiSds%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=I9UoZewcd3CnZvOAnoIzFWoA%2B0PjI3fI%2BQmbWNpkhys%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=P67MVT8NeuJJWFC%2B4Pfprx9EsbMzQ%2Bu5JE55wEqJf7I%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/engine_spans_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/engine_spans_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl?sv=2019-02-02&sr=b&sig=1CE51TXB85LbPJxsVs6gl5fXLFjlYqRQDhK2THyD1l8%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/python_span_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/dataprep/python_span_cbc02dff-4a8f-49ba-b88b-c17da72b29d2.jsonl?sv=2019-02-02&sr=b&sig=4O3hI0XUU5soUneRpGadu21V%2BQgZLgxy7axfzbYKfZ8%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=X3MScOukrRQjrBofw%2Fau1bnP6UFGSwoXbtRfsTVWnYs%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.capstone-project_1609018810_472dcd8d/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=K2mm%2FTiCZKu4LThG5rBsHYNA%2F8vbMhmch4qmmCkmnqM%3D&st=2020-12-26T21%3A37%3A40Z&se=2020-12-27T05%3A47%3A40Z&sp=r'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperdrive Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1609014252219
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling( {\n",
    "        \"--C\": uniform(0.50,1.00),\n",
    "       \"--max_iter\" : choice(10,20,30)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "\n",
    "\n",
    "#sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='./conda_dependencies.yml')\n",
    "#envit = Environment.get(workspace=ws,name='myenv')\n",
    "\n",
    "#config  = ScriptRunConfig(source_directory='.',\n",
    "                        # script='train.py',\n",
    "                        # compute_target=cpu_cluster,\n",
    "                         #environment=envit)\n",
    "\n",
    "\n",
    "\n",
    "#hyperdrive_run_config = <your config here>\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "                                   hyperparameter_sampling = ps,\n",
    "                                   primary_metric_name = 'Accuracy',\n",
    "                                   max_total_runs = 12,\n",
    "                                   max_concurrent_runs = 4,\n",
    "                                   primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                   policy = policy,\n",
    "                                   run_config = config)\n",
    "\n",
    "#estimator=estimator use to replace estimator in hyperdriveconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1609015780425
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cb27ba1f0145238c5650019102d480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/capstone-project/runs/HD_e62be9af-049a-4068-8698-5ed62e21b7bf?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131891/workspaces/quick-starts-ws-131891\", \"run_id\": \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf\", \"run_properties\": {\"run_id\": \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf\", \"created_utc\": \"2020-12-26T21:49:25.031576Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"9989203e-a8d9-43af-bcaf-4f467538cd90\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"12\", \"max_total_jobs\": \"12\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"uniform\\\", [0.5, 1.0]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"uniform\\\", [0.5, 1.0]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourceGroups/aml-quickstarts-131891/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-131891/experiments/capstone-project\\\", \\\"SubscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-131891\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-131891\\\", \\\"ExperimentName\\\": \\\"capstone-project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"puru-compute-new\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": \\\"AzureML-Tutorial\\\", \\\"version\\\": \\\"60\\\", \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-core==1.19.0\\\", \\\"azureml-defaults==1.19.0\\\", \\\"azureml-telemetry==1.19.0\\\", \\\"azureml-train-restclients-hyperdrive==1.19.0\\\", \\\"azureml-train-core==1.19.0\\\", \\\"azureml-widgets==1.19.0\\\", \\\"azureml-pipeline-core==1.19.0\\\", \\\"azureml-pipeline-steps==1.19.0\\\", \\\"azureml-opendatasets==1.19.0\\\", \\\"azureml-automl-core==1.19.0\\\", \\\"azureml-automl-runtime==1.19.0\\\", \\\"azureml-train-automl-client==1.19.0\\\", \\\"azureml-train-automl-runtime==1.19.0\\\", \\\"azureml-train-automl==1.19.0\\\", \\\"azureml-train==1.19.0\\\", \\\"azureml-sdk==1.19.0\\\", \\\"azureml-interpret==1.19.0\\\", \\\"azureml-tensorboard==1.19.0\\\", \\\"azureml-mlflow==1.19.0\\\", \\\"mlflow\\\", \\\"sklearn-pandas\\\"]}, \\\"pandas\\\", \\\"numpy\\\", \\\"tqdm\\\", \\\"scikit-learn\\\", \\\"matplotlib\\\"], \\\"name\\\": \\\"azureml_a1736710baabf05d37337a101fa8d6d1\\\"}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": null, \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9989203e-a8d9-43af-bcaf-4f467538cd90\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"f19aebfe-4f78-431e-b7be-596660ec4b79\\\", \\\"amlClientSessionId\\\": \\\"a7cbff0d-6584-4667-ae09-994b30749f65\\\", \\\"subscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 12, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourceGroups/aml-quickstarts-131891/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-131891/experiments/capstone-project\\\", \\\"SubscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-131891\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-131891\\\", \\\"ExperimentName\\\": \\\"capstone-project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"puru-compute-new\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": \\\"AzureML-Tutorial\\\", \\\"version\\\": \\\"60\\\", \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-core==1.19.0\\\", \\\"azureml-defaults==1.19.0\\\", \\\"azureml-telemetry==1.19.0\\\", \\\"azureml-train-restclients-hyperdrive==1.19.0\\\", \\\"azureml-train-core==1.19.0\\\", \\\"azureml-widgets==1.19.0\\\", \\\"azureml-pipeline-core==1.19.0\\\", \\\"azureml-pipeline-steps==1.19.0\\\", \\\"azureml-opendatasets==1.19.0\\\", \\\"azureml-automl-core==1.19.0\\\", \\\"azureml-automl-runtime==1.19.0\\\", \\\"azureml-train-automl-client==1.19.0\\\", \\\"azureml-train-automl-runtime==1.19.0\\\", \\\"azureml-train-automl==1.19.0\\\", \\\"azureml-train==1.19.0\\\", \\\"azureml-sdk==1.19.0\\\", \\\"azureml-interpret==1.19.0\\\", \\\"azureml-tensorboard==1.19.0\\\", \\\"azureml-mlflow==1.19.0\\\", \\\"mlflow\\\", \\\"sklearn-pandas\\\"]}, \\\"pandas\\\", \\\"numpy\\\", \\\"tqdm\\\", \\\"scikit-learn\\\", \\\"matplotlib\\\"], \\\"name\\\": \\\"azureml_a1736710baabf05d37337a101fa8d6d1\\\"}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20201113.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": null, \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9989203e-a8d9-43af-bcaf-4f467538cd90\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"f19aebfe-4f78-431e-b7be-596660ec4b79\\\", \\\"amlClientSessionId\\\": \\\"a7cbff0d-6584-4667-ae09-994b30749f65\\\", \\\"subscriptionId\\\": \\\"61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 12, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-12-26T21:49:25.989496\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-12-26T21:49:25.989496\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"6229ca14809074531add181b3bbbebe723518666949e5c1e55cd40ad75283363\\\"\", \"progress_metadata_digest\": \"\\\"6229ca14809074531add181b3bbbebe723518666949e5c1e55cd40ad75283363\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-12-26T21:49:25.989496\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-12-26T21:49:25.989496\\\"\", \"_aml_system_HD_e62be9af-049a-4068-8698-5ed62e21b7bf_0\": \"{\\\"--C\\\": 0.7041092604516455, \\\"--max_iter\\\": 20}\", \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_0\": \"{\\\"--C\\\": 0.7041092604516455, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_e62be9af-049a-4068-8698-5ed62e21b7bf_1\": \"{\\\"--C\\\": 0.6094887670790725, \\\"--max_iter\\\": 20}\", \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_1\": \"{\\\"--C\\\": 0.6094887670790725, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_e62be9af-049a-4068-8698-5ed62e21b7bf_2\": \"{\\\"--C\\\": 0.980331094996977, \\\"--max_iter\\\": 20}\", \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_2\": \"{\\\"--C\\\": 0.980331094996977, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_e62be9af-049a-4068-8698-5ed62e21b7bf_3\": \"{\\\"--C\\\": 0.5773696800562127, \\\"--max_iter\\\": 10}\", \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_3\": \"{\\\"--C\\\": 0.5773696800562127, \\\"--max_iter\\\": 10}\", \"_aml_system_environment_preparation_status\": \"PREPARING\", \"environment_preparation_status\": \"PREPARING\", \"_aml_system_prepare_run_id\": \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_preparation\", \"prepare_run_id\": \"HD_e62be9af-049a-4068-8698-5ed62e21b7bf_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg131891.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_e62be9af-049a-4068-8698-5ed62e21b7bf/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=mjkVIlrxT9CWzu1uELBcmSYC0NJcx%2BeTnXinKFxpRNE%3D&st=2020-12-26T21%3A39%3A29Z&se=2020-12-27T05%3A49%3A29Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:00:25\", \"hyper_parameters\": {\"--C\": [\"uniform\", [0.5, 1.0]], \"--max_iter\": [\"choice\", [[10, 20, 30]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2020-12-26T21:49:25.399382][API][INFO]Experiment created\\r\\n[2020-12-26T21:49:26.542073][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2020-12-26T21:49:26.220269][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2020-12-26T21:49:27.3649704Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_e62be9af-049a-4068-8698-5ed62e21b7bf\n",
      "Web View: https://ml.azure.com/experiments/capstone-project/runs/HD_e62be9af-049a-4068-8698-5ed62e21b7bf?wsid=/subscriptions/61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30/resourcegroups/aml-quickstarts-131891/workspaces/quick-starts-ws-131891\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2020-12-26T21:49:25.399382][API][INFO]Experiment created<END>\\n\"\"<START>[2020-12-26T21:49:26.542073][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\"<START>[2020-12-26T21:49:26.220269][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2020-12-26T21:49:27.3649704Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
     ]
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "hyperdrive_run = exp.submit(hyperdrive_config)\n",
    "RunDetails(hyperdrive_run).show()\n",
    "# wait for completion\n",
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1609015818594
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Id:  HD_7c0e747a-1ba4-4332-84c9-25baec00c4a7_0\n",
      "\n",
      " Accuracy: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1609015900209
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surjamodel\tsurjamodel:1\t1\n"
     ]
    }
   ],
   "source": [
    "# register model for future deployment\n",
    "# os.makedirs('outputs', exist_ok=True)\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "hyperdrive_model = best_run.register_model(model_name='surjamodel',\n",
    "                                                      model_path='.',\n",
    "                                                      model_framework = Model.Framework.SCIKITLEARN,\n",
    "                                                      model_framework_version='0.19.1',\n",
    "                                                      resource_configuration= ResourceConfiguration(cpu =1, memory_in_gb=0.5)\n",
    "                                                     )\n",
    "\n",
    "print(hyperdrive_model.name, hyperdrive_model.id, hyperdrive_model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1609015907071
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(workspace=Workspace.create(name='quick-starts-ws-131891', subscription_id='61c5c3f0-6dc7-4ed9-a7f3-c704b20e3b30', resource_group='aml-quickstarts-131891'), name=surjamodel, id=surjamodel:1, version=1, tags={}, properties={})\n"
     ]
    }
   ],
   "source": [
    "print(hyperdrive_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running.............................................................\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 09d50524-32a9-4a45-81ab-ed93d2435775\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"AciDeploymentFailed\",\n",
      "  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"AciDeploymentFailed\",\n",
      "      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":5,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-12-25T18:43:40.754Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-12-25T18:43:46.452Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:50Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:40:00Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:46Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b71207778e3aa6cea102fa317559ab76b8bc1830654216a748db5e13c52d6f07.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 09d50524-32a9-4a45-81ab-ed93d2435775\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":5,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-12-25T18:43:40.754Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-12-25T18:43:46.452Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:50Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:40:00Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:46Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b71207778e3aa6cea102fa317559ab76b8bc1830654216a748db5e13c52d6f07.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 09d50524-32a9-4a45-81ab-ed93d2435775\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":5,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2020-12-25T18:43:40.754Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2020-12-25T18:43:46.452Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:25Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:25Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:28Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:28Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:50Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:43:40Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:40:00Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:43:46Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Killing\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Killing container with id b71207778e3aa6cea102fa317559ab76b8bc1830654216a748db5e13c52d6f07.\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9dfb571e7011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"puruservice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswagger_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 915\u001b[0;31m                                                       logs_response, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    916\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    917\u001b[0m                                                                                   operation_state))\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 09d50524-32a9-4a45-81ab-ed93d2435775\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\"restartCount\\\":5,\\\"currentState\\\":{\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"},\\\"previousState\\\":{\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2020-12-25T18:43:40.754Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2020-12-25T18:43:46.452Z\\\",\\\"detailStatus\\\":\\\"Error\\\"},\\\"events\\\":[{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:25Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:39:28Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:39:50Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:40Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"},{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2020-12-25T18:40:00Z\\\",\\\"lastTimestamp\\\":\\\"2020-12-25T18:43:46Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id b71207778e3aa6cea102fa317559ab76b8bc1830654216a748db5e13c52d6f07.\\\",\\\"type\\\":\\\"Normal\\\"}]}\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 09d50524-32a9-4a45-81ab-ed93d2435775\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: puruservice. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\\\n3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n4. View the diagnostic events to check status of container, it may help you to debug the issue. {\\\\\\\"restartCount\\\\\\\":5,\\\\\\\"currentState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off restarting failed\\\\\\\"},\\\\\\\"previousState\\\\\\\":{\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2020-12-25T18:43:40.754Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2020-12-25T18:43:46.452Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"},\\\\\\\"events\\\\\\\":[{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:25Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:25Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:28Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:28Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"viennaglobal.azurecr.io/azureml/azureml_d97f122bdcaea8212b2eadb5cef56a6d:latest\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:39:50Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:43:40Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"},{\\\\\\\"count\\\\\\\":6,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:40:00Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2020-12-25T18:43:46Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Killing\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Killing container with id b71207778e3aa6cea102fa317559ab76b8bc1830654216a748db5e13c52d6f07.\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}]}\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "envit = Environment.get(workspace = ws, name=\"AzureML-Tutorial\")\n",
    "envit.python.conda_dependencies.add_pip_package(\"scikit-learn\")\n",
    "model = Model(ws,name='puru-model')\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4, enable_app_insights=True, auth_enabled=True)\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=envit)\n",
    "\n",
    "service = Model.deploy(ws, \"puruservice\", [model], inference_config, deployment_config=aci_config)\n",
    "service.wait_for_deployment(show_output = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "payload = json.dumps({\n",
    "    'data': x_data[0:2].tolist(),\n",
    "    'method': 'predict_proba'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "scoringuri = ''\n",
    "key = ''\n",
    "data= { \"data\" :\n",
    "       [\n",
    "           {\n",
    "               \n",
    "           },\n",
    "           {\n",
    "               \n",
    "           }\n",
    "       ]\n",
    "    }\n",
    "input_data = json.dumps(data)\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "response = requests.post(scoringuri, input_data, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print logs\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "# Requires the config to be downloaded first to the current working directory\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Set with the deployment name\n",
    "name = \"puruservice\"\n",
    "\n",
    "# load existing web service\n",
    "service = Webservice(name=name, workspace=ws)\n",
    "logs = service.get_logs()\n",
    "\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
